# Overview of OnlySq models
OnlySq offers a wide range of models for various user needs. All models supports "system" role for more customisation.
You can get json of models by using:

<span style="color: white; background-color: #2e7d32; padding: 0.2em 0.5em; border-radius: 5px; font-size: 0.8em; font-weight: bold;">GET</span> https://api.onlysq.ru/ai/models

---

# ChatGPT models
ChatGPT is a free and easy-to-use app that can help you with writing, learning, brainstorming, and more.

| Model name      | Description                                                                                                                                                                                                                                                                                | Type     | Modality | Endpoints                                                                        |
| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | -------- | -------- | -------------------------------------------------------------------------------- |
| `gpt-4o-mini`   | A small model with superior textual intelligence and multimodal reasoning                                                                                                                                                                                                                  | Keys     | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a> |
| `gpt-4o`        | GPT‑4o (“o” for “omni”) is a step towards much more natural human-computer interaction                                                                                                                                                                                                     | Provider | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a>                                             |
| `gpt-4`         | GPT-4 is OpenAI’s most advanced system, producing safer and more useful responses                                                                                                                                                                                                          | Provider | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a>                                             |
| `o3-mini`       | OpenAI o3‑mini is first small reasoning model that supports highly requested developer features including function calling⁠(opens in a new window), Structured Outputs⁠(opens in a new window), and developer messages⁠(opens in a new window), making it production-ready out of the gate | Provider | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a>                                             |
| `gpt-3.5-turbo` | GPT-3.5-turbo is a fast, cost-effective version of GPT-3.5, optimized for dialogue and general tasks with broad capabilities but less powerful than GPT-4.                                                                                                                                 | Provider | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a>                                             |

# DeepSeek models
Deepseek is a series of large language models developed by the company Deepseek, known for their strong performance in code generation, reasoning, and natural language tasks.

| Model name    | Description                                                                                                                                                                                                                              | Type     | Modality | Endpoints                           |
| ------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------- | -------- | ----------------------------------- |
| `deepseek-r1` | Deepseek-R1 is a specialized AI model by Deepseek, optimized for reasoning and code generation tasks, with strong performance in logical problem-solving and programming. It’s designed to handle complex, multi-step tasks efficiently. | Provider | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a> |
| `deepseek-v3` | Deepseek-V3 is an advanced AI model by Deepseek, excelling in reasoning, code generation, and multi-step problem-solving. It builds on prior versions with enhanced capabilities for complex tasks and improved efficiency.              | Provider | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a> |

# Llama models
Llama is a series of open-source large language models developed by Meta. Known for their versatility and multilingual support, Llama models excel in natural language understanding, code generation, and reasoning tasks.

| Model name  | Description                                                                                                                                                                                                                         | Type     | Modality | Endpoints                           |
| ----------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------- | -------- | ----------------------------------- |
| `llama-3.3` | Llama-3.3 is an advanced iteration of Meta's Llama series, featuring enhanced reasoning, multilingual support, and improved efficiency for complex tasks like coding and natural language understanding.                            | Provider | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a> |
| `llama-3.1` | Llama-3.1 is an updated version of Meta's Llama series, offering improved performance in natural language understanding, code generation, and multi-language support, with a focus on scalability and efficiency for various tasks. | Provider | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a> |
# Claude models
Claude is a series of large language models developed by Anthropic, known for their strong natural language understanding, reasoning, and code generation capabilities.

| Model name          | Description                                                                                                                                                                                                                | Type     | Modality | Endpoints                           |
| ------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------- | -------- | ----------------------------------- |
| `claude-3.5-sonnet` | Claude-3.5-Sonnet is a powerful AI model by Anthropic, excelling in natural language tasks, reasoning, and code generation, with a focus on safety, accuracy, and handling complex, multi-step problems.                   | Provider | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a> |
| `claude-3-haiku`    | Claude-3-Haiku is a compact, fast, and cost-efficient AI model by Anthropic, designed for simple tasks with a focus on speed and affordability while maintaining strong language understanding and reasoning capabilities. | Provider | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a> |
# Le Chat models
Mistral is a series of open-weight large language models developed by Mistral AI, known for their efficiency, scalability, and strong performance in natural language tasks, reasoning, and code generation.

| Model name          | Description                                                                                                                                                                                                            | Type     | Modality | Endpoints                            |
| ------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------- | -------- | ------------------------------------ |
| `mistral-small-3.1` | Mistral-Small-3.1 is a compact, efficient variant of the Mistral series, designed for cost-effective and fast performance on simpler tasks while maintaining strong language understanding and reasoning capabilities. | Keys     | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a> |
# Qwen models
Qwen is a series of large language models developed by Alibaba Cloud, designed for versatility and high performance across a wide range of tasks.

| Model name                   | Description                                                                                                                                                                                                              | Type     | Modality | Endpoints                                |
| ---------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | -------- | -------- | ---------------------------------------- |
| `qwen3-235b-a22b`            | A large-scale language model with 235 billion parameters, designed for complex reasoning, multi-step tasks, and high-accuracy applications.                                                                              | Keys     | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a><br> |
| `qwen3-30b-a3b`              | A powerful LLM with 30 billion parameters, optimized for advanced natural language understanding, code generation, and multi-modal tasks.                                                                                | Keys     | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a><br> |
| `qwen3-32b`                  | A 32-billion-parameter version of Qwen3, offering strong performance in text generation, logical reasoning, and coding tasks.                                                                                            | Keys     | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a><br> |
| `qwen-max-latest`            | The most capable and up-to-date version of Qwen, ideal for handling complex, multi-step tasks with high accuracy.                                                                                                        | Keys     | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a><br> |
| `qwen-plus-2025-01-25`       | A balanced model released on January 25, 2025, offering strong performance across a wide range of tasks at a moderate cost.                                                                                              | Keys     | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a><br> |
| `qwq-32b`                    | A research prototype focusing on advanced reasoning capabilities, particularly excelling in math and code generation.                                                                                                    | Keys     | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a><br> |
| `qwen-turbo-2025-02-11`      | A lightweight and fast model released on February 11, 2025, optimized for simple, cost-effective tasks requiring quick responses.                                                                                        | Keys     | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a><br> |
| `qwen2.5-omni-7b`            | A 7-billion-parameter multi-modal model capable of processing both text and images for integrated understanding and generation.                                                                                          | Keys     | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a><br> |
| `qvq-72b-preview-0310`       | A preview version of a 72-billion-parameter model, featuring enhanced reasoning and generation capabilities for advanced tasks.                                                                                          | Keys     | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a><br> |
| `qwen2.5-vl-32b-instruct`    | A vision-language model with 32 billion parameters, fine-tuned to understand and generate responses from visual inputs like images.                                                                                      | Keys     | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a><br> |
| `qwen2.5-14b-instruct-1m`    | A 14-billion-parameter model trained to handle long-context tasks, supporting input lengths up to 1 million tokens.                                                                                                      | Keys     | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a><br> |
| `qwen2.5-coder-32b-instruct` | A specialized 32B model fine-tuned for code generation and programming-related tasks, supporting multiple programming languages.                                                                                         | Keys     | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a><br> |
| `qwen2.5-72b-instruct`       | A 72-billion-parameter instruction-following model with strong capabilities in natural language understanding and generation.                                                                                            | Keys     | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a><br> |
| `qwen`                       | Qwen is a large language model developed by Alibaba Cloud, excelling in natural language understanding, code generation, and multi-language support, with a focus on versatility and handling complex tasks efficiently. | Provider | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a>     |

# Google models
Gemini is a series of large language models developed by Google, known for their advanced reasoning, natural language understanding, and multimodal capabilities.

| Model name                            | Description                                                                                                                                                                                                                                         | Type | Modality | Endpoints                                                                        |
| ------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---- | -------- | -------------------------------------------------------------------------------- |
| `gemini-2.5-flash`                    | A fast and efficient version of Google's Gemini model, optimized for real-time, low-latency tasks while maintaining strong multi-modal understanding.                                                                                               | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a> |
| `gemini-2.5-flash-lite-preview-06-17` | A lightweight preview release of the Gemini Flash model from June 17, designed for cost-effective, high-speed inference on less complex tasks.                                                                                                      | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a> |
| `gemini-2.0-flash`                    | A fast, efficient model optimized for quick responses and cost-effective tasks while maintaining strong performance.                                                                                                                                | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a> |
| `gemini-2.0-flash-lite`               | A lighter version of `gemini-2.0-flash`, prioritizing speed and lower resource usage for simpler tasks.                                                                                                                                             | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a> |
| `gemini-1.5-flash`                    | A fast and capable model from the 1.5 series, designed for general-purpose tasks with a balance of speed and accuracy.                                                                                                                              | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a> |
| `gemini-1.5-flash-8b`                 | A smaller, 8-billion-parameter variant of `gemini-1.5-flash`, offering faster inference for less complex tasks.                                                                                                                                     | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a> |
| `gemini-1.5-pro`                      | A high-performance model in the `1.5` series, optimized for complex, multi-step tasks requiring advanced reasoning and precision.                                                                                                                   | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a> |
| `gemma-3-4b-it`                       | `gemma-3-4b-it` is a 4-billion-parameter model from the Gemma series, optimized for instructional tasks (IT). It provides strong performance in natural language understanding and task-specific applications, balancing efficiency and capability. | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a> |
# Cohere models
Command is a specialized AI model developed by Cohere, designed for understanding and executing commands or instructions effectively. It focuses on task-specific applications, such as interpreting user inputs, automating workflows, and performing actions based on natural language commands.

| Model name               | Description                                                                                                                                               | Type | Modality | Endpoints                                                                                                                    |
| ------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------- | ---- | -------- | ---------------------------------------------------------------------------------------------------------------------------- |
| `command-a-03-2025`      | A future iteration of the Command model, likely optimized for advanced text generation and conversational tasks.                                          | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a><br><a href="/docs/openaisdk">OpenAI SDK</a> |
| `command-r7b-12-2024`    | A specialized version of the Command-R series, potentially focusing on reasoning or command execution with specific improvements.                         | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a>                                             |
| `command-r-plus-04-2024` | An enhanced variant of Command-R+, designed for superior reasoning and task-specific applications.                                                        | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a>                                             |
| `command-r-plus`         | An advanced version of the Command-R model, emphasizing improved reasoning and execution capabilities.                                                    | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a>                                             |
| `command-r-08-2024`      | A version of the Command-R model released in August 2024, optimized for interpreting and executing commands.                                              | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a>                                             |
| `command-r-03-2024`      | A March 2024 release of the Command-R model, focused on command-driven tasks and automation.                                                              | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a>                                             |
| `command-r`              | The standard Command-R model, tailored for understanding and executing instructions effectively.                                                          | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a>                                             |
| `command`                | The foundational Command model, designed for general-purpose text generation, conversations, and question-answering.                                      | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a>                                             |
| `command-nightly`        | A nightly build of the Command model, offering the latest experimental features and updates.                                                              | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a>                                             |
| `command-light`          | A lightweight version of the Command model, optimized for speed and efficiency in resource-constrained environments.                                      | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a>                                             |
| `command-light-nightly`  | A nightly build of the lightweight Command model, providing rapid updates and experimental features for lightweight use cases.                            | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a>                                             |
| `c4ai-aya-expanse-32b`   | A large-scale model (32 billion parameters) developed by C4AI, likely designed for expansive reasoning, complex tasks, and high-performance applications. | Keys | Text     | <a href="/docs/endpoint2">API2.0</a><br><a href="/docs/openaisdk">OpenAI SDK</a>                                             |
# Image models
Image Models are AI models designed for tasks involving images, such as recognition, segmentation, generation, enhancement, and style transfer.

| Model name  | Description                                                                                                                                   | Type | Modality | Endpoints                         |
| ----------- | --------------------------------------------------------------------------------------------------------------------------------------------- | ---- | -------- | --------------------------------- |
| `Kandinsky` | Kandinsky is a series of multimodal AI models developed by Sber, designed for generating and processing images based on textual descriptions. | Keys | Images   | <a href="/docs/imagen">ImaGen</a> |
